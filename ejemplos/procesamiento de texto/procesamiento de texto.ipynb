{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    <p> <center ><img src=\"https://mcd.unison.mx/wp-content/themes/awaken/img/logo_mcd.png\" width=\"100\" align=\"center\"> </center> </p>\n",
    "\n",
    "<center>\n",
    "    <h1>Procesamiento de texto</h1>\n",
    "\n",
    "    **Ingeniería de Características**\n",
    "\n",
    "    **MCD/UNISON **\n",
    "\n",
    "    [Julio Waissman Vilanova](http://mat.uson.mx/~juliowaissman/) (julio.waissman@unison.mx)\n",
    "</center>\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de texto \n",
    "\n",
    "## Ingeniería de Características \n",
    "\n",
    "### Maestría en Ciencia de Datos \n",
    "### Universidad de Sonora\n",
    "\n",
    "\n",
    "\n",
    "#### Julio Waissman Vilanova (julio.waissman@unison.mx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El correcto procesamiento de texto es un paso escencial para cualquier tarea de Procesamiento del Lenguaje Natural (PLN). En no pocas ocasiones, la calidad de los resultados se encuentra intimamente relacionada con ésta tarea. Sin embargo, después de la obtención de documentos (una tarea aún más ingrata) esta es una de las tareas menos glamorosa. \n",
    "\n",
    "Hay una serie de desiciones que hay que tomar desde esta etapa, y algunas veces es necesario volver a estas instancias para poder obtener un resultado satisfactorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Normalización\n",
    "\n",
    "### Expresiones regulares en python\n",
    "\n",
    "La limpieza de texto es un paso crucial, el cual se da a lo largo de todo el procesamiento de texto. Vamos a revisar algunos de los métodos más usuales basados en reglas, los cuales tienen que ver con el manejo de expresiones regulares. Para mayor información sobre expresiones regulares y su uso en *python* se puede consultar el material siguiente:\n",
    "\n",
    "- Un [*acordeon* del módulo `re` de *python*](https://www.dataquest.io/blog/large_files/python-regular-expressions-cheat-sheet.pdf). \n",
    "\n",
    "- Un [tutorial en español sobre el uso de `re`](https://relopezbriega.github.io/blog/2015/07/19/expresiones-regulares-con-python/)\n",
    "\n",
    "El compilador de expresiones regulares viene con varias banderas de compilación, entre las que destacan `re.I` (para ignorar el uso de mayúsculas y minúsculas); `re.S`, para que el punto signifique cualquier caracter, incluido `\\n` (muy práctico en la secuancia `.*` en multiples lineas); `re.M` que permite la búsqueda en múltiples lineas, afectando la operación de los caracteres `^` y `$`; y por último `re.X` para poder representar la expresión regular en forma *verbose* (o verborreica). \n",
    "\n",
    "Vamos a hacer algunos ejemplos de expresiones regulares para practicar. Primero, vamos a compilar y explicar algunas fórmulas que típicamente son muy útiles en PLN. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "email_re = re.compile(r\"\"\"\n",
    "\\b               # comienzo de delimitador de palabra\n",
    "[\\w][\\w\\.-]*     # Cualquier caracter alfanumerico seguido de uno o mas caracteres mas los signos (. -)\n",
    "@                # seguido de @\n",
    "\\w[\\w\\.-]*       # cualquier caracter alfanumerico mas los signos (.-)\n",
    "\\.               # seguido de .\n",
    "[a-zA-Z]{2,6}    # dominio de alto nivel: 2 a 6 letras en minúsculas o mayúsculas.\n",
    "\\b               # fin de delimitador de palabra\n",
    "\"\"\", re.X)\n",
    "\n",
    "url_re = re.compile(r\"\"\"\n",
    "\\b                  # delimitador de palabra\n",
    "(\\w+:\\/{2})?        # caracteres iniciales (http, https, ftp, ...) seguidos de // (uno o ninguno)\n",
    "[\\d\\w-]+            # cualquier caracter alfanumerico mas -\n",
    "(\\.[\\d\\w-]+)+       # seguido de uno o mas dominios, que empiezan con punto y siguen con caracteres\n",
    "(/\\S+)*             # cualquier serie de caracteres separados por / y sin espacios en blanco\n",
    "\\b                  # delimitador de palabra\n",
    "\"\"\", re.X) \n",
    "\n",
    "insulto_re = re.compile(r\"\"\"\n",
    "([#%&\\*\\$]{2,})     # al menos dos simbolos típicos para poner insultos\n",
    "(\\w*)               # seguidos de letras\n",
    "\"\"\", re.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y a hora vamos a probar algunos de estas expresiones regulares. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texto_en_bruto =\"\"\"\n",
    "Como la mayoría sabréis, un sitio Web “normal” tiene una URL en este formato: \n",
    "http://www.ordenadores-y-portatiles.com. Habrás notado que www.ordenadores-y-portatiles.com \n",
    "sigue llegando sin ningún problema al sitio. que es diferente que\n",
    "www.ordenadores-y-portatiles.com/una%20rireccion/de%20prueba/pagina.html\n",
    "Nos podemos encontrar otros formatos como es el caso de FTP, como por ejemplo \n",
    "ftp.microsoft.com en modo comando o ftp://ftp.microsoft.com si lo ponemos en un \n",
    "navegador de Internet. Tambien se puede accesar por su IP como en  217.76.130.207, \n",
    "\n",
    "Para los correos electrónicos, si tienes uno en gmail, lo puede poner como\n",
    "juliowaissman@gmail.com, JulioWaissman@gmail.com, julio.waissman@gmail.com,\n",
    "Julio.Waissman@gmail.com, y todos te llevan al mismo lado. Igual se puede tener\n",
    "correos un poco extraños como w234QWSA.dojdnn_wsda@unison.edu.mx, y deberíamos\n",
    "poder reconocerlos (entre otros)\n",
    "\"\"\"\n",
    "\n",
    "procesado, n = re.subn(email_re, \":CORREO:\", texto_en_bruto)\n",
    "procesado, n = re.subn(url_re, \":URL:\", procesado)\n",
    "print(\"\\nY el texto, substituyendo correos electrónicos y url queda como:\\n\")\n",
    "print(procesado)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a hacer algunas expresiones regulares para detectar emoticones (algo particularmente útil en tratamiento de textos en redes sociales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_gde_feliz_re = re.compile(r' [8x;:=]-?(?:\\)|\\}|\\]|>){2,}')\n",
    "emo_chi_feliz_re = re.compile(r' (?:[;:=]-?[\\)\\}\\]d>])|(?:<3)|(?:XOXO)')\n",
    "emo_gde_triste_re = re.compile(r' [x:=]-?(?:\\(|\\[|\\||\\\\|/|\\{|<){2,}')\n",
    "emo_chi_triste_re = re.compile(r' [x:=]-?[\\(\\[\\|\\\\/\\{<]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inventa un texto en bruto con diferentes emojis y substituye los emojis por los tokens `:BHAPPY:`, `:SHAPPY:`, `BSAD:`, `:SSAD` segun corresponda.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Inserta tu código aqui ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a utilizar las expresiones regulares para tratar un conjunto de documentos, para utilizarlos posteriormente en una tarea de ciencia de datos. Vamos a usar los datos de los tweets del concurso TASS 2015 que se encuentran disponibles para el desarrollo y prueba de sistemas de análisis de sentimientos de manera libre. Para esto, vamos a procesar el corupus de entrenamiento,el cual viene en formato `xml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import pandas as pd\n",
    "\n",
    "archivo = \"general-tweets-train-tagged.xml\"\n",
    "\n",
    "arbol = et.parse(archivo)\n",
    "raiz = arbol.getroot()\n",
    "data_dic = []\n",
    "for tweet in raiz.iter('tweet'):\n",
    "    contenido = tweet.find('content').text\n",
    "    if contenido is not None:\n",
    "        data_dic.append({\n",
    "            'texto': contenido,\n",
    "            'polaridad': tweet.find('sentiments')[0].find('value').text,\n",
    "            'id': tweet.find('tweetid').text,\n",
    "            'usuario': '@' + tweet.find('user').text,\n",
    "            'fecha': tweet.find('date').text,\n",
    "            'tópicos': '[' + ', '.join(['\"' + t.text + '\"' for t in tweet.find('topics')]) + ']'\n",
    "        })\n",
    "df_train = pd.DataFrame.from_dict(data_dic)\n",
    "display(df_train.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y vamos a quedarnos sólo con el texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [documento for documento in df_train['texto'].values]\n",
    "print('Conjunto con {} entradas de tweeter para ser tratadas'.format(len(x_train)))\n",
    "\n",
    "x_train[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y el conjunto debera tener 7,218 entradas.\n",
    "\n",
    "Ahora que ya tenemos los datos de entrada es necesario tratarlos. Para esto, es muy importante que se traten de forma homogenea, y que la forma en que los tratamos sea fácil de exportar, con el fin que sea reproducible. Es por esto que el tratamiento debe de ser siempre realizado en forma de función. Vamos a tratar nuestro texto en una función `prepara_texto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a tratar que ver que significa cada expresión regular\n",
    "\n",
    "usuarios_re = re.compile(r\"@[\\w\\d]+\")\n",
    "hashtags_re = re.compile(r\"#[\\w\\d]+\")\n",
    "\n",
    "remplaza_por_espacios_re = re.compile('[\\n/(){}\\[\\]\\|@,;\\.]')\n",
    "\n",
    "simbolos_a_eliminar_re = re.compile('[^\\d\\w #+_]')\n",
    "\n",
    "def prepara_texto(texto):\n",
    "    text = texto.lower()\n",
    "    \n",
    "    # Codificaciones (problemas con UTF-8, latin1, etc...)\n",
    "    text = re.sub(r'\\\\\\\\', r'\\\\', text)\n",
    "    text = re.sub(r'\\\\\\\\', r'\\\\', text)\n",
    "    text = re.sub(r'\\\\x\\w{2,2}', ' ', text)\n",
    "    text = re.sub(r'\\\\u\\w{4,4}', ' ', text)\n",
    "    text = re.sub(r'\\\\n', ' . ', text)\n",
    "\n",
    "    # Cambia e_mails, urls y usuarios por palabra clave\n",
    "    text = re.sub(email_re, '_EMAIL_', text)\n",
    "    text = re.sub(url_re, '_URL_', text)\n",
    "    text = re.sub(usuarios_re, '_USR_', text)\n",
    "    text = re.sub(hashtags_re, '_HASHTAG_', text)\n",
    "    \n",
    "    # Elimina etiquetas de marcaje tipo xml\n",
    "    # (no se requiere en este caso pero solo para dejar el tip)\n",
    "    #text = BeautifulSoup(text, \"lxml\").get_text() \n",
    "  \n",
    "    # Las palabras con letras repetidas más de 3 veces \n",
    "    # (dos veces por las personas que abusan demasiado)\n",
    "    text = re.sub(r'([a-zA-Z])\\1\\1+(\\w*)', r'\\1\\1\\2', text)\n",
    "    text = re.sub(r'([a-zA-Z])\\1\\1+(\\w*)', r'\\1\\1\\2', text)\n",
    "    \n",
    "    # Elimina simbolos\n",
    "    text = re.sub(remplaza_por_espacios_re, ' ', text)\n",
    "    text = re.sub(simbolos_a_eliminar_re, '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a normalizar nuestros documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_prep = [prepara_texto(documento) for documento in x_train]\n",
    "x_train_prep[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así como estos ejemplos, existen otros casos en los cuales se pueden establecer reglas, basadas o no en \n",
    "expresiones regulares. Algunos casos son:\n",
    "\n",
    "1. Etiquetas de marcaje (Markdown, $\\LaTeX$, ...). \n",
    "\n",
    "2. Eliminación de apostrofes\n",
    "\n",
    "3. Argot y neologísmos\n",
    "\n",
    "Igualmente, la puntuación puede mantenerse en algunos casos (por ejemplo, los signos de exclamación e interrogación). Por otra parte, usuarios, url, correos electrónicos y demás, pueden ser eliminados en lugar de mantenerlos con una palabra clave (o inclusive, pueden ser mantenidos tal cual, si la base de datos es suficientemente amplia y el nombre del usuario es fundamental para inferir el contexto).\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
