{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMqV5MG6pkIg"
      },
      "source": [
        "<center>\n",
        "<p><img src=\"https://mcd.unison.mx/wp-content/themes/awaken/img/logo_mcd.png\" width=\"150\">\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "<h1>Curso Ingeniería de Características</h1>\n",
        "\n",
        "<h3>Nube de palabras y uso de Spacy</h3>\n",
        "\n",
        "\n",
        "<p> Julio Waissman Vilanova </p>\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mcd-unison/ing-caract/blob/main/ejemplos/tipos/python/nube_informe.ipynb\"><img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\"  width=\"30\" /> Ejecuta en Colab</a>\n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKTi65X3tqJh"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "En esta libreta vamos a ver como hacer nubes de palabras como un pretexto para ver como usar la biblioteca `spacy` en la limpieza de lenguaje natural (procesamiento sencillo).\n",
        "\n",
        "\n",
        "Como un ejemplo de aplicación actual (al momento de hacer la libreta, claro). Vamos a utilizar el [Discurso del presidente Andrés Manuel López Obrador durante el Quinto Informe de Gobierno](https://www.gob.mx/presidencia/articulos/version-estenografica-5-informe-de-gobierno?idiom=es).\n",
        "\n",
        "![](https://lopezobrador.org.mx/wp-content/uploads/2023/08/banner_quinto_informe-1.jpg)\n",
        "\n",
        "Este tipo de estudio se puede aplicar a cualquier versión estenográfica o a cualquier informa. Y da un poco la idea de los temas más importantes tratados. Si bien los resultados son a tomar con precaución, las nubes de palabra suelen generar impacto.\n",
        "\n",
        "Carguemos primero las bibliotecas que vamos ausar y algunas configuraciones de base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yhAUMcvrLhE"
      },
      "outputs": [],
      "source": [
        "# !pip install requests\n",
        "# !pip install spacy\n",
        "# !python -m spacy download es_core_news_md\n",
        "# !pip install beautifulsoup4\n",
        "# !pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx1bbZuzpiE2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import wordcloud\n",
        "\n",
        "nlp = spacy.load('es_core_news_md')\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = (15, 7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akWSmNekviV5"
      },
      "source": [
        "## Descargando el texto\n",
        "\n",
        "Vamos a usar `requests` para descargar la página completa como datos crudos, y luego utilizaremos `BeautifulSoup` para extraer del archivo el texto en parágrafor. Cáda parágrafo lo vamos a guardar en una entrada de un `dataframe`, por si luego decidimos hacer otro tipo de análisis con la información.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HW7MkudwGwl"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.gob.mx/presidencia/articulos/version-estenografica-5-informe-de-gobierno.html\"\n",
        "\n",
        "informe_html = requests.get(url)\n",
        "sopa = BeautifulSoup(informe_html.text)\n",
        "\n",
        "contenido = sopa.find_all(\"div\", {\"class\":\"article-body\"})\n",
        "df_informe = pd.DataFrame({\n",
        "    'Parrafo': [parrafo.text for parrafo in contenido[0].find_all(\"p\")] \n",
        "})\n",
        "\n",
        "df_informe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LorE9aS058M"
      },
      "source": [
        "Vamos a evitar lineas que contienen caractéres alfanumericos, así como las lineas que sabemos no son parte del informe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ntu8PgX1GPi"
      },
      "outputs": [],
      "source": [
        "df_informe = df_informe[df_informe.Parrafo.str.contains(r\"\\w\", regex=True)]\n",
        "df_informe = df_informe[~df_informe.Parrafo.str.startswith(('MODERADORA', 'PRESIDENTE', '(HONORES)', 'VOCES'))]\n",
        "df_informe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bw-ohs13G6Z"
      },
      "source": [
        "## Haciendo una nube de palabras *rápido y furioso*\n",
        "\n",
        "Ahora vamos autilizar el texto tal cual lo tenemos para hacer una nube de palabras, usando solo lo que nos ofrece la biblioteca de [`wordcloud`](https://amueller.github.io/word_cloud).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekJQSgWW4gfU"
      },
      "outputs": [],
      "source": [
        "# Primero vamos a ver la funcionalidad básica\n",
        "# de la clase WordCloud\n",
        "wordcloud.WordCloud?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "YUtkSlWJ5Cq8",
        "outputId": "11094ab5-64bf-4dd4-ada0-6024aa2b511f"
      },
      "outputs": [],
      "source": [
        "texto = '\\n'.join(df_informe.Parrafo.str.lower().values)\n",
        "\n",
        "# Genera la nube de palabras\n",
        "wc = wordcloud.WordCloud().generate(texto)\n",
        "\n",
        "# Muestra la nube de palabras\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFRj4XoL7Iz0"
      },
      "source": [
        "Pues muy bonita pero muy inutil. El problema más grande de esta nube de palabras es que se hizo tomando en cuenta todas las palabras, y la mayoría de las que más se repiten no dan información.\n",
        "\n",
        "Vamos entonces a usar la serie de palabras de paro que nos da `spacy` con el modelo en español que bajamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "PCA7RFhf7dCk",
        "outputId": "26cdbab1-ee9f-4809-c466-87813d5f6988"
      },
      "outputs": [],
      "source": [
        "palabras_paro = nlp.Defaults.stop_words\n",
        "\n",
        "# Genera la nube de palabras\n",
        "wc = wordcloud.WordCloud(\n",
        "    stopwords=palabras_paro\n",
        ").generate(texto)\n",
        "\n",
        "# Muestra la nube de palabras\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiQRQlCD9TaJ"
      },
      "source": [
        "Y pues algo mejor, pero vemos que se siguen usando paabras que en otro contexto serían palabras significativas, pero que en un informa son muy esperables. Por ejemplo: México, o las que tengan que ver con porcentajes y con cantidades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "OC4QAxcX9Sf8",
        "outputId": "4d07c264-b32d-4dee-d60f-af4a8c84aa38"
      },
      "outputs": [],
      "source": [
        "# Actualizamos palabras a mano\n",
        "palabras_paro.update([\n",
        "  \"México\", \"país\", \"gobierno\",\n",
        "  \"año\", \"años\", \"mil\", \"millones\", \n",
        "  \"pesos\", \"dolares\", \"dólares\", \"ciento\", 'a', 'y', 'o'\n",
        "])\n",
        "\n",
        "# Genera la nube de palabras\n",
        "wc = wordcloud.WordCloud(\n",
        "    stopwords=palabras_paro\n",
        ").generate(texto)\n",
        "\n",
        "# Muestra la nube de palabras\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fku611mV-bwk"
      },
      "source": [
        "Un poco mejor, pero podemos ajustar mejor los tamaños de las letras y otros detalles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "LHqtxSL3-yTJ",
        "outputId": "9b6d6c14-7ac4-4c29-b644-388781087fee"
      },
      "outputs": [],
      "source": [
        "# Una mascara redonda de radio dado en pixeles\n",
        "radio = 200\n",
        "largo = int(1.2 * radio)\n",
        "x, y = np.ogrid[:2*largo, :2*largo]\n",
        "mascara_redonda = (x - largo) ** 2 + (y - largo) ** 2 > radio ** 2\n",
        "mascara_redonda = 255 * mascara_redonda.astype(int)\n",
        "\n",
        "\n",
        "# Genera la nube de palabras\n",
        "wc = wordcloud.WordCloud(\n",
        "    stopwords=palabras_paro,\n",
        "    max_words=100,\n",
        "    max_font_size=50,\n",
        "    background_color=\"black\",\n",
        "    #mask= mask\n",
        ").generate(texto)\n",
        "\n",
        "# Muestra la nube de palabras\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Si te gusta lo puedes guardad\n",
        "wc.to_file(\"nube.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN69Zyo2Cqt3"
      },
      "source": [
        "## Usando `spacy`para extraer mejores características\n",
        "\n",
        "Vamos ahora a utilizar spacy y su capacidad para tratar tokens de forma automñatica para extraer diferentes características importantes del informe y revisar como procesar texto con spacy.\n",
        "\n",
        "Por ejemplo, vamos a ver que adjetivos utilizó el presidente en su discurso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "Bw7_nfjEGV6h",
        "outputId": "9ea61264-1e31-43f5-f755-10cc3a5e4ea1"
      },
      "outputs": [],
      "source": [
        "texto = '\\n'.join(df_informe.Parrafo.values)\n",
        "doc = nlp(texto)\n",
        "\n",
        "palabras = ' '.join(\n",
        "    [ \n",
        "     token.norm_ for token in doc\n",
        "     if token.is_alpha and not token.like_num and not token.is_stop and\n",
        "        not token.is_currency and token.pos_ in ['ADJ']\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Genera la nube de palabras\n",
        "wc = wordcloud.WordCloud().generate(palabras)\n",
        "\n",
        "# Muestra la nube de palabras\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpvyRI8yHVoK"
      },
      "source": [
        "¿Y que verbos utilizó el presidente? ¿Se puede sacar alguna conclusión? ¿Cambia si se usan los verbos en infinitivo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "braENa9lHhBS",
        "outputId": "55c68f35-7cbb-4857-fa9a-0f8af2979a65"
      },
      "outputs": [],
      "source": [
        "verbos = ' '.join(\n",
        "  [token.norm_ for token in doc if token.pos_ in ['VERB']]\n",
        ")\n",
        "\n",
        "verbos_inf = ' '.join(\n",
        "  [token.lemma_ for token in doc if token.pos_ in ['VERB']]\n",
        ")\n",
        "\n",
        "\n",
        "# Genera la nube de palabras\n",
        "wc = wordcloud.WordCloud().generate(verbos)\n",
        "wc2 = wordcloud.WordCloud().generate(verbos_inf)\n",
        "\n",
        "# Muestra la nube de palabras\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(2,1,2)\n",
        "plt.imshow(wc2, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBAXHVFgKC1W"
      },
      "source": [
        "¿Y su usamos puros sustantivos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "61l0TbToKXp3",
        "outputId": "6a2a1f17-874d-4937-e340-e88c849be96a"
      },
      "outputs": [],
      "source": [
        "palabras = ' '.join(\n",
        "    [ \n",
        "     token.norm_ for token in doc\n",
        "     if token.is_alpha and not token.like_num and not token.is_stop and\n",
        "        not token.is_currency and token.pos_ in ['NOUN']\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Genera la nube de palabras\n",
        "wc = wordcloud.WordCloud().generate(palabras)\n",
        "\n",
        "# Muestra la nube de palabras\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urvWSfBWKyIv"
      },
      "source": [
        "¿Y por nombres propios?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "2YASg55uK3d-",
        "outputId": "7c2de76b-3493-49c7-9144-df9d57489633"
      },
      "outputs": [],
      "source": [
        "palabras = ' '.join(\n",
        "    [ \n",
        "     token.text for token in doc\n",
        "     if token.is_alpha and not token.like_num and not token.is_stop and\n",
        "        not token.is_currency and token.pos_ in ['PROPN'] \n",
        "    ]\n",
        ")\n",
        "\n",
        "# Genera la nube de palabras\n",
        "wc = wordcloud.WordCloud().generate(palabras)\n",
        "\n",
        "# Muestra la nube de palabras\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVihZnBNKI3r"
      },
      "source": [
        "¿Y que tal si pudiermos ver los lugares que más mencionó? ¿Y si los ponemos en una imagen con el controno del país?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "from PIL import Image\n",
        "\n",
        "mexico_img = \"mapa-mexico.png\"\n",
        "mapa_url = \"https://github.com/mcd-unison/ing-caract/raw/main/ejemplos/tipos/python/mapa-mexico.png\"\n",
        "urllib.request.urlretrieve(mapa_url, mexico_img)\n",
        "\n",
        "mask =  np.array(Image.open(mexico_img))[:,:,0]\n",
        "mask[mask != 0] = 10\n",
        "mask[mask == 0] = 255\n",
        "plt.imshow(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora si, listos para hacer nuestra nube de palabras con el perfil de México. Por cierto el perfil de México es pésimo para hacer nubes de palabras, pero el del estado de Sonora está que ni mandado a hacer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "i8M5YvrhMpT9",
        "outputId": "0cda394f-d6c7-472f-f272-483ce667a74b"
      },
      "outputs": [],
      "source": [
        "lugares = {}\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ in ['LOC'] and ent.label_:\n",
        "        lugares[ent.text] = lugares.get(ent.text, 0) + 1\n",
        "\n",
        "# Genera la nube de palabras\n",
        "wc = wordcloud.WordCloud(mask=mask, background_color=\"white\", contour_color='blue').generate_from_frequencies(lugares)\n",
        "\n",
        "# Muestra la nube de palabras\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copia de nube_informe",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 ('spacy')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "daaccbbb69cdcdc36d8badad722b04e86f94953e099575e6c632dde4ed7f1a8c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
